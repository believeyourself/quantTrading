"""
åˆçº¦å†å²æ•°æ®å½’æ¡£ç®¡ç†å™¨
è´Ÿè´£ç®¡ç†åˆçº¦å…¥æ± å‡ºæ± æ—¶çš„æ•°æ®å½’æ¡£ï¼Œæ”¯æŒæŒ‰ä¼šè¯åŒºåˆ†æ¯æ¬¡å…¥æ± å‡ºæ± çš„ç‰¹å¾åˆ†æ
"""

import os
import json
import shutil
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from utils.logger import get_logger

logger = get_logger(__name__)

class ContractArchiveManager:
    """åˆçº¦å†å²æ•°æ®å½’æ¡£ç®¡ç†å™¨"""
    
    def __init__(self):
        self.archive_dir = "cache/archive"
        self.sessions_dir = os.path.join(self.archive_dir, "sessions")
        self.summary_dir = os.path.join(self.archive_dir, "summary")
        self.current_history_dir = "cache/monitor_history"
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(self.sessions_dir, exist_ok=True)
        os.makedirs(self.summary_dir, exist_ok=True)
        
        # å½’æ¡£ç´¢å¼•æ–‡ä»¶
        self.index_file = os.path.join(self.summary_dir, "archive_index.json")
        self.sessions_summary_file = os.path.join(self.summary_dir, "contract_sessions.json")
        
        # åŠ è½½å½’æ¡£ç´¢å¼•
        self.archive_index = self._load_archive_index()
        self.sessions_summary = self._load_sessions_summary()
    
    def _load_archive_index(self) -> Dict:
        """åŠ è½½å½’æ¡£ç´¢å¼•"""
        if os.path.exists(self.index_file):
            try:
                with open(self.index_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"åŠ è½½å½’æ¡£ç´¢å¼•å¤±è´¥: {e}")
        return {
            "last_session_id": 0,
            "total_sessions": 0,
            "last_updated": datetime.now().isoformat()
        }
    
    def _load_sessions_summary(self) -> Dict:
        """åŠ è½½ä¼šè¯æ‘˜è¦"""
        if os.path.exists(self.sessions_summary_file):
            try:
                with open(self.sessions_summary_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logger.warning(f"åŠ è½½ä¼šè¯æ‘˜è¦å¤±è´¥: {e}")
        return {}
    
    def _save_archive_index(self):
        """ä¿å­˜å½’æ¡£ç´¢å¼•"""
        try:
            self.archive_index["last_updated"] = datetime.now().isoformat()
            with open(self.index_file, 'w', encoding='utf-8') as f:
                json.dump(self.archive_index, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜å½’æ¡£ç´¢å¼•å¤±è´¥: {e}")
    
    def _save_sessions_summary(self):
        """ä¿å­˜ä¼šè¯æ‘˜è¦"""
        try:
            with open(self.sessions_summary_file, 'w', encoding='utf-8') as f:
                json.dump(self.sessions_summary, f, ensure_ascii=False, indent=2)
        except Exception as e:
            logger.error(f"ä¿å­˜ä¼šè¯æ‘˜è¦å¤±è´¥: {e}")
    
    def _generate_session_id(self, symbol: str) -> str:
        """ç”Ÿæˆä¼šè¯ID"""
        self.archive_index["last_session_id"] += 1
        session_id = f"{datetime.now().strftime('%Y-%m-%d')}_{symbol}_session_{self.archive_index['last_session_id']:03d}"
        return session_id
    
    def archive_contract_exit(self, symbol: str, exit_reason: str = "manual") -> Optional[str]:
        """
        åˆçº¦å‡ºæ± æ—¶å½’æ¡£æ•°æ®
        
        Args:
            symbol: åˆçº¦åç§°
            exit_reason: å‡ºæ± åŸå› 
            
        Returns:
            å½’æ¡£çš„ä¼šè¯IDï¼Œå¦‚æœå½’æ¡£å¤±è´¥è¿”å›None
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æœ‰å½“å‰å†å²æ•°æ®
            current_history_file = os.path.join(self.current_history_dir, f"{symbol}_history.json")
            if not os.path.exists(current_history_file):
                logger.warning(f"åˆçº¦ {symbol} æ²¡æœ‰å†å²æ•°æ®æ–‡ä»¶ï¼Œè·³è¿‡å½’æ¡£")
                return None
            
            # è¯»å–å½“å‰å†å²æ•°æ®
            with open(current_history_file, 'r', encoding='utf-8') as f:
                history_data = json.load(f)
            
            if not history_data.get('history'):
                logger.warning(f"åˆçº¦ {symbol} å†å²æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡å½’æ¡£")
                return None
            
            # ç”Ÿæˆä¼šè¯ID
            session_id = self._generate_session_id(symbol)
            
            # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
            history_records = history_data['history']
            entry_time = history_records[-1]['timestamp']  # æœ€æ—©çš„è®°å½•
            exit_time = history_records[0]['timestamp']    # æœ€æ–°çš„è®°å½•
            
            # è®¡ç®—èµ„é‡‘è´¹ç‡ç»Ÿè®¡
            funding_rates = [record.get('funding_rate', 0) for record in history_records]
            entry_funding_rate = funding_rates[-1]  # å…¥æ± æ—¶çš„èµ„é‡‘è´¹ç‡
            exit_funding_rate = funding_rates[0]     # å‡ºæ± æ—¶çš„èµ„é‡‘è´¹ç‡
            max_funding_rate = max(funding_rates)
            min_funding_rate = min(funding_rates)
            avg_funding_rate = sum(funding_rates) / len(funding_rates)
            
            # è®¡ç®—ä»·æ ¼ç»Ÿè®¡
            mark_prices = [record.get('mark_price', 0) for record in history_records]
            entry_price = mark_prices[-1]  # å…¥æ± æ—¶çš„ä»·æ ¼
            exit_price = mark_prices[0]    # å‡ºæ± æ—¶çš„ä»·æ ¼
            max_price = max(mark_prices)
            min_price = min(mark_prices)
            
            # è®¡ç®—æŒç»­æ—¶é—´
            try:
                entry_dt = datetime.fromisoformat(entry_time.replace('Z', '+00:00'))
                exit_dt = datetime.fromisoformat(exit_time.replace('Z', '+00:00'))
                duration_minutes = int((exit_dt - entry_dt).total_seconds() / 60)
            except:
                duration_minutes = 0
            
            # æ„å»ºå½’æ¡£æ•°æ®
            archive_data = {
                "session_id": session_id,
                "symbol": symbol,
                "entry_time": entry_time,
                "exit_time": exit_time,
                "duration_minutes": duration_minutes,
                "entry_funding_rate": entry_funding_rate,
                "exit_funding_rate": exit_funding_rate,
                "max_funding_rate": max_funding_rate,
                "min_funding_rate": min_funding_rate,
                "avg_funding_rate": avg_funding_rate,
                "entry_price": entry_price,
                "exit_price": exit_price,
                "max_price": max_price,
                "min_price": min_price,
                "total_records": len(history_records),
                "exit_reason": exit_reason,
                "created_time": datetime.now().isoformat(),
                "history": history_records
            }
            
            # ä¿å­˜å½’æ¡£æ–‡ä»¶
            archive_filename = f"{session_id}.json"
            archive_filepath = os.path.join(self.sessions_dir, archive_filename)
            
            with open(archive_filepath, 'w', encoding='utf-8') as f:
                json.dump(archive_data, f, ensure_ascii=False, indent=2)
            
            # æ›´æ–°ä¼šè¯æ‘˜è¦
            if symbol not in self.sessions_summary:
                self.sessions_summary[symbol] = []
            
            # æ·»åŠ ä¼šè¯æ‘˜è¦ï¼ˆä¸åŒ…å«å®Œæ•´å†å²æ•°æ®ï¼‰
            session_summary = {
                "session_id": session_id,
                "entry_time": entry_time,
                "exit_time": exit_time,
                "duration_minutes": duration_minutes,
                "entry_funding_rate": entry_funding_rate,
                "exit_funding_rate": exit_funding_rate,
                "max_funding_rate": max_funding_rate,
                "min_funding_rate": min_funding_rate,
                "avg_funding_rate": avg_funding_rate,
                "entry_price": entry_price,
                "exit_price": exit_price,
                "max_price": max_price,
                "min_price": min_price,
                "total_records": len(history_records),
                "exit_reason": exit_reason,
                "created_time": datetime.now().isoformat()
            }
            
            self.sessions_summary[symbol].append(session_summary)
            
            # æ›´æ–°å½’æ¡£ç´¢å¼•
            self.archive_index["total_sessions"] += 1
            
            # ä¿å­˜ç´¢å¼•å’Œæ‘˜è¦
            self._save_archive_index()
            self._save_sessions_summary()
            
            logger.info(f"âœ… åˆçº¦ {symbol} å‡ºæ± æ•°æ®å·²å½’æ¡£ï¼Œä¼šè¯ID: {session_id}")
            logger.info(f"ğŸ“Š å½’æ¡£ç»Ÿè®¡: æŒç»­æ—¶é—´ {duration_minutes}åˆ†é’Ÿï¼Œè®°å½•æ•° {len(history_records)}ï¼Œèµ„é‡‘è´¹ç‡èŒƒå›´ [{min_funding_rate:.4f}, {max_funding_rate:.4f}]")
            
            return session_id
            
        except Exception as e:
            logger.error(f"âŒ åˆçº¦ {symbol} å‡ºæ± å½’æ¡£å¤±è´¥: {e}")
            return None
    
    def archive_contract_entry(self, symbol: str, entry_reason: str = "auto") -> Optional[str]:
        """
        åˆçº¦å…¥æ± æ—¶è®°å½•å…¥æ± ä¿¡æ¯
        
        Args:
            symbol: åˆçº¦åç§°
            entry_reason: å…¥æ± åŸå› 
            
        Returns:
            ä¼šè¯IDï¼Œå¦‚æœè®°å½•å¤±è´¥è¿”å›None
        """
        try:
            # ç”Ÿæˆä¼šè¯ID
            session_id = self._generate_session_id(symbol)
            
            # è®°å½•å…¥æ± ä¿¡æ¯
            entry_data = {
                "session_id": session_id,
                "symbol": symbol,
                "entry_time": datetime.now().isoformat(),
                "entry_reason": entry_reason,
                "status": "active",
                "created_time": datetime.now().isoformat()
            }
            
            # ä¿å­˜å…¥æ± è®°å½•
            entry_filename = f"{session_id}_entry.json"
            entry_filepath = os.path.join(self.sessions_dir, entry_filename)
            
            with open(entry_filepath, 'w', encoding='utf-8') as f:
                json.dump(entry_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… åˆçº¦ {symbol} å…¥æ± è®°å½•å·²ä¿å­˜ï¼Œä¼šè¯ID: {session_id}")
            
            return session_id
            
        except Exception as e:
            logger.error(f"âŒ åˆçº¦ {symbol} å…¥æ± è®°å½•å¤±è´¥: {e}")
            return None
    
    def get_contract_sessions(self, symbol: str) -> List[Dict]:
        """è·å–æŒ‡å®šåˆçº¦çš„æ‰€æœ‰ä¼šè¯æ‘˜è¦"""
        return self.sessions_summary.get(symbol, [])
    
    def get_session_detail(self, session_id: str) -> Optional[Dict]:
        """è·å–æŒ‡å®šä¼šè¯çš„è¯¦ç»†ä¿¡æ¯"""
        try:
            session_file = os.path.join(self.sessions_dir, f"{session_id}.json")
            if os.path.exists(session_file):
                with open(session_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return None
        except Exception as e:
            logger.error(f"è·å–ä¼šè¯ {session_id} è¯¦æƒ…å¤±è´¥: {e}")
            return None
    
    def get_archive_statistics(self) -> Dict:
        """è·å–å½’æ¡£ç»Ÿè®¡ä¿¡æ¯"""
        try:
            total_sessions = self.archive_index.get("total_sessions", 0)
            total_contracts = len(self.sessions_summary)
            
            # è®¡ç®—å„åˆçº¦çš„ä¼šè¯æ•°
            contract_session_counts = {}
            for symbol, sessions in self.sessions_summary.items():
                contract_session_counts[symbol] = len(sessions)
            
            # è®¡ç®—å¹³å‡ä¼šè¯æŒç»­æ—¶é—´
            all_durations = []
            for sessions in self.sessions_summary.values():
                for session in sessions:
                    if 'duration_minutes' in session:
                        all_durations.append(session['duration_minutes'])
            
            avg_duration = sum(all_durations) / len(all_durations) if all_durations else 0
            
            return {
                "total_sessions": total_sessions,
                "total_contracts": total_contracts,
                "contract_session_counts": contract_session_counts,
                "average_duration_minutes": avg_duration,
                "last_updated": self.archive_index.get("last_updated", ""),
                "archive_directory": self.archive_dir
            }
            
        except Exception as e:
            logger.error(f"è·å–å½’æ¡£ç»Ÿè®¡å¤±è´¥: {e}")
            return {}
    
    def cleanup_old_archives(self, days_to_keep: int = 30):
        """æ¸…ç†æ—§çš„å½’æ¡£æ•°æ®"""
        try:
            cutoff_date = datetime.now().timestamp() - (days_to_keep * 24 * 60 * 60)
            cleaned_count = 0
            
            for filename in os.listdir(self.sessions_dir):
                if filename.endswith('.json'):
                    filepath = os.path.join(self.sessions_dir, filename)
                    if os.path.getmtime(filepath) < cutoff_date:
                        os.remove(filepath)
                        cleaned_count += 1
            
            logger.info(f"âœ… æ¸…ç†äº† {cleaned_count} ä¸ªè¶…è¿‡ {days_to_keep} å¤©çš„å½’æ¡£æ–‡ä»¶")
            
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§å½’æ¡£å¤±è´¥: {e}")


# å…¨å±€å½’æ¡£ç®¡ç†å™¨å®ä¾‹
archive_manager = ContractArchiveManager()
